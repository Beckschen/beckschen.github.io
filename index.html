<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-7580334-2');
  </script>

  <title>Jieneng Chen</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  
  <meta name="author" content="Jieneng Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="icon" type="image/png" href="myimages/icon_jhu.jpeg">
<style>
        body,
        td,
        th,
        tr,
        p,
        a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 16px;
        }

        body {
            background-color: white;
            margin: 0;
            padding: 0;
        }

        .container {
            width: 100%;
            max-width: 1100px;
            margin: 0 auto;
            padding: 20px;
        }

        name {
            font-size: 32px;
            font-weight: bold;
        }

        heading {
            font-size: 22px;
            font-weight: bold;
        }

        .intro-section {
            text-align: center;
            padding: 40px 20px;
        }

        .intro-section name {
            display: block;
            margin-bottom: 10px;
        }

        .intro-section p {
            margin: 10px auto;
            max-width: 800px;
            line-height: 1.6;
        }

        .research-grid {
            margin-top: 40px;
        }

        .research-block {
            margin-bottom: 40px;
            padding: 20px;
            border: 1px solid #e0e0e0;
            background-color: #fafafa;
        }

        .foundation-block {
            max-width: 1020px;
            margin-left: auto;
            margin-right: auto;
        }

        .block-header {
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #333;
        }

        .block-title {
            font-size: 18px;
            font-weight: bold;
            color: #333;
        }

        .two-column {
            max-width: 1020px;
            margin-left: auto;
            margin-right: auto;
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-bottom: 40px;
        }

        .project-item {
            margin-bottom: 20px;
        }

        .project-name {
            font-weight: bold;
            color: #000;
            margin-bottom: 5px;
        }

        .project-desc {
            color: #666;
            font-size: 15px;
            line-height: 1.5;
        }

        .navyblue {
            color: #000080;
            text-decoration: none;
        }

        .navyblue:hover {
            text-decoration: underline;
        }

        .arrow-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: -80px 0 0px 0;
            max-width: 1020px;
            margin-left: auto;
            margin-right: auto;
        }

        .arrow {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 10px;
        }

        .arrow-icon {
            font-size: 40px;
            color: #666;
        }

        @media screen and (max-width: 768px) {
            /* 保持双栏布局，但减小间距 */
            .two-column {
                grid-template-columns: 1fr 1fr;
                gap: 15px;
                padding: 0 10px;
            }

            /* 保持箭头容器双栏 */
            .arrow-container {
                grid-template-columns: 1fr 1fr;
                gap: 15px;
                margin: -60px 10px 0px 10px;
            }
            
            /* 调整字体大小以适应小屏幕 */
            body, td, th, tr, p, a {
                font-size: 13px;
            }
            
            name {
                font-size: 24px;
            }
            
            heading {
                font-size: 18px;
            }

            .block-title {
                font-size: 14px;
            }

            .research-block {
                padding: 12px;
            }

            /* 调整内部文字大小 */
            .research-block div[style*="font-size: 14px"] {
                font-size: 12px !important;
            }

            .research-block div[style*="font-size: 13px"] {
                font-size: 11px !important;
            }

            .research-block span[style*="font-size: 12px"] {
                font-size: 10px !important;
            }

            /* 调整箭头大小 */
            .arrow-icon {
                font-size: 28px;
            }

            .research-block div[style*="font-size: 32px"] {
                font-size: 24px !important;
            }

            /* 调整内部框的padding */
            .research-block > div[style*="padding: 15px"] {
                padding: 10px !important;
            }

            .container {
                padding: 10px;
            }
        }

        /* 针对超小屏幕（如iPhone SE）的额外优化 */
        @media screen and (max-width: 400px) {
            .two-column {
                gap: 10px;
                padding: 0 5px;
            }

            .arrow-container {
                gap: 10px;
                margin: -50px 5px 0px 5px;
            }

            .research-block {
                padding: 10px;
            }

            .block-title {
                font-size: 13px;
            }

            .research-block div[style*="font-size: 14px"] {
                font-size: 11px !important;
            }

            .research-block div[style*="font-size: 13px"] {
                font-size: 10px !important;
            }

            .research-block span[style*="font-size: 12px"] {
                font-size: 9px !important;
            }

            br {
                display: none;
            }
        }
    </style>
 <meta charset="UTF-8">
 <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Envelope Icon</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
</head>

  <table style="width:100%;max-width:1100px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jieneng Chen</name>
                  <p style="text-align:center; margin-top: 6px;">
                Email: jchen293 [at] jh.edu
              </p>
              </p>
              <p>I'm a final-year Ph.D. candidate in <a href="https://www.cs.jhu.edu/", class="black">Computer Science</a> at <a href="https://www.jhu.edu/", class="black">Johns Hopkins University</a>, advised by Distinguished Professor <a href="http://www.cs.jhu.edu/~ayuille/", class="navyblue">Alan Yuille</a>.
                I am also named a Siebel Scholar, the highest distinction in bioengineering at Hopkins. I am best known for my neural architecture <a href="https://arxiv.org/pdf/2102.04306", class="navyblue">TransUNet</a>, which introduced Transformers into biomedical image analysis for the first time and has since catalyzed a large research community, inspiring over 10,000 subsequent papers.</p>

                I am fascinated by how intelligence can operate in the real world. My research builds scalable, structured world models that connect artificial and natural intelligence, enabling new forms of reasoning and interaction across computer vision, robotics, and healthcare.
              </p>
              <p>
                I love mentoring and teaching undergraduates. I am appointed as an Instructor to teach Machine Imagination (EN.601.208) at Johns Hopkins in 2025/2026.
                </p>
              <p style="text-align:center">
                </br>
                <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
                <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
                
                <!-- <a href="https://scholar.google.com/citations?hl=en&user=yLYj88sAAAAJ"><i class="ai ai-google-scholar ai-3x" style='font-size:30px'></i>&nbsp &nbsp -->
                <!-- <a href="mailto:jienengchen01@gmail.com"><i class="fa fa-envelope" style='font-size:29px'></i>&nbsp &nbsp -->
                <!-- <a href="https://github.com/Beckschen"><i class="fa fa-github" style='font-size:30px'></i>&nbsp &nbsp -->
                <!-- <a href="https://www.linkedin.com/in/jieneng-chen-53254011a/"><i class="fa fa-linkedin" style='font-size:30px'></i>&nbsp &nbsp -->

                  <a href="mailto:jchen293@jh.edu" class="navyblue">Email</a> / <a href="./Jieneng_Chen_CV.pdf" class="navyblue">CV</a> / <a href="https://scholar.google.com/citations?hl=en&user=yLYj88sAAAAJ" class="navyblue">Google Scholar</a> / <a href="https://github.com/Beckschen" class="navyblue">Github</a> / <a href="https://www.linkedin.com/in/jieneng-chen-53254011a/" class="navyblue">Linkedin</a> 

              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="myimages/photo.jpg"><img style="width:80%;max-width:80%;padding:0;border-radius: 10%;border:1px solid #f2f3f3" alt="profile photo" src="myimages/photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:10px;width:100%;vertical-align:middle">
                <heading>Awards</heading>
              </td>
            </tr>
          </tbody>
        </table>

    <ul style="list-style-type: none; padding-left: 20px;">
        <!-- <li style="margin-bottom: 4px;"> <i class="fa fa-microphone" style="color: #4169E1; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">invited talk at <a href="https://iaifi.org/about.html", class="navyblue">NSF IAIFI</a> on physics & AI in Boston.</span> -->
      <li style="margin-bottom: 4px;"> <i class="fa fa-award" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;"><a href="https://www.businesswire.com/news/home/20240920559594/en/Siebel-Scholars-Foundation-Announces-Class-of-2025", class="darkred">Siebel scholar award</a>, class 2025 ($35k independent award).</span>
      <li style="margin-bottom: 4px;"> <i class="fa fa-award" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">MICCAI 2025 <font color="DarkRed">doctoral thesis award</font>.</span> 
        <li style="margin-bottom: 4px;"> <i class="fa fa-award" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">MICCAI 2025 <font color="DarkRed">best paper award</font> (runner-up; 2 out of 1,027 accepted papers). </span>
        <li style="margin-bottom: 4px;"> <i class="fa fa-award" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">KDD 2025 <a href="https://cccblog.org/2025/08/18/blue-sky-track-winners-at-acm-sigkdd-2025-health-day/?utm_source=feedblitz&utm_medium=FeedBlitzRss&utm_campaign=cccblog", class="navyblue">CCC</a> <font color="DarkRed">best paper award</font>.
      <li style="margin-bottom: 4px;"> <img src="images/nvidia-logo.svg" alt="NVIDIA logo" style="width: 20px; vertical-align: middle;" /> <span style="vertical-align: middle;">NVIDIA 2025 academic grant award ($100k award in compute).</span>
      <li style="margin-bottom: 4px;"> <i class="fa fa-users" style="color: #32CD32; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">3 NSF travel awards for CVPR/WACV/FG doctoral consortium (outstanding PhD students). </span> 
      <li style="margin-bottom: 4px;"> <i class="fa fa-award" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">2025 visionary award, LLM for material science.</span> 
      <li style="margin-bottom: 4px;"> <i class="fa fa-award" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">RSNA 2025 certificate of merit award.</span> 
<!--       <li style="margin-bottom: 4px;"> <i class="fa fa-award" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">Lambda-sponsored compute grant to advance benchmarks for <a href="https://beckschen.github.io/cvpr26wmas", class="navyblue">active sensing world models</a>.</span>  -->
      <li style="margin-bottom: 4px;"> <i class="fa fa-award" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">DAAD AInet fellowship.</span> 
      <li style="margin-bottom: 4px;"> <i class="fa fa-award" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">Kempner fellowship ($300k independent research fellowship).</span> 
        
      <!-- <li style="margin-bottom: 4px;"> <i class="fa fa-star" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;"><a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yLYj88sAAAAJ&citation_for_view=yLYj88sAAAAJ:dhFuZR0502QC", class="navyblue">TransUNet</a> is listed as <a href="https://gist.github.com/sergicastellasape/185f72fece3bb489f79366908594504d", class="navyblue">top 15 cited 2021 paper in all AI fields</a> (the top 1 alphafold has won the nobel prize).</span>
      <li style="margin-bottom: 4px;"> <i class="fa fa-star" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;"><a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yLYj88sAAAAJ&citation_for_view=yLYj88sAAAAJ:BqipwSGYUEgC", class="navyblue">SwinUNet</a> is listed as <a href="https://scholar.google.com/citations?hl=en&vq=en&view_op=list_hcore&venue=cwIh2C-xo8kJ.2024", class="navyblue">top 3 most cited ECCV papers in five years in Google Metrics</a>.</span> -->
    </ul>

    <br>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:10px;width:100%;vertical-align:middle">
                <heading>Mentorship highlight</heading>
              </td>
            </tr>
          </tbody>
        </table>

    <ul style="list-style-type: none; padding-left: 20px;">
        <li style="margin-bottom: 4px;"> <i class="fa fa-star" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">My mentee's paper has been selected for an Oral Presentation at ICLR 2026 (top 4% of accepted papers or 1% of submissions).  Congrats, <a href="https://me.jiahanzhang.top/", class="navyblue">Jiahan</a>!</span>
        <li style="margin-bottom: 4px;"> <i class="fa fa-star" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">Undergraduate mentee was a finalist (1 of 24 nationwide) for the <a href="https://cra.org/about/awards/outstanding-undergraduate-researcher-award/#tab-id-2", class="navyblue">CRA Outstanding Undergraduate Researcher Award</a>. Congrats, <a href="https://taiminglu.com/", class="navyblue">TaiMing</a>!</span>
        <li style="margin-bottom: 4px;"> <i class="fa fa-star" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">Undergraduate mentee received an Honorable Mention for the <a href="https://cra.org/about/awards/outstanding-undergraduate-researcher-award/", class="navyblue">Outstanding Undergraduate Researcher Award</a>. Congrats, <a href="https://ardauzunoglu.github.io/", class="navyblue">Arda</a>!</span>
        <li style="margin-bottom: 4px;"> <i class="fa fa-star" style="color: #FFD700; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">Undergraduate mentee won <a href="https://www.cs.jhu.edu/news/celebrating-the-2025-department-and-school-awardees/", class="navyblue">Michael J. Muuss Research Award</a>. Congrats, <a href="https://taiminglu.com/", class="navyblue">TaiMing</a>!</span>
    </ul>

    <br>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:10px;width:100%;vertical-align:middle">
                                    <heading>Research Areas</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- <center> -->
                        <p style="padding-left: 20px;"> Over the next decade, my research aims to answer a central question: how can we bring intelligence into the real world to meaningfully benefit humanity? </p>
     
                        <p style="padding-left: 20px;">This pursuit is structured across three pillars:</p>
                        <ul style="padding-left: 40px;"> 
                              <li style="margin-bottom: 8px;">Building Foundation Neural Architectures to learn scalable representations from raw sensory data.</li>
                              <li style="margin-bottom: 8px;">Establishing Predictive Visual Modeling grounded in human-like mental models to achieve closed-loop embodiment. </li>
                              <li style="margin-bottom: 8px;">Developing Proactive Biomedical Systems via medical world models to reduce cancer mortality and enhance human life. </li>
                              <!-- (2) Predictive Visual Intelligence by developing dynamic, embodied World Models that use analysis-by-synthesis to enable agents to reason about, explore, and manipulate the physical world in closed-loop; (3) Concurrently, I will channel these predictive capabilities into Proactive Biomedical Intelligence, creating Medical World Models that simulate complex biological processes like cancer evolution, ultimately transforming healthcare from reactive diagnosis to personalized, proactive treatment planning and discovery. </p>  -->
                        </ul>
                        <br>

                    <div class="two-column">
                        <!-- Block 1: Predictive Embodied Intelligence -->
                        <div class="research-block">
                            <div class="block-header">
                                <div class="block-title">Predictive Modeling for Vision and Embodiment</div>
                            </div>
                            
                            <!-- Flowchart -->
                            <div style="display: grid; grid-template-columns: 1fr auto 1fr; gap: 15px; align-items: center; margin-bottom: 25px; padding: 15px; background: white; border: 1px solid #ddd; border-radius: 8px;">
                                <!-- Left: Human Mental Models -->
                                <div style="text-align: center;">
                                    <div style="font-weight: bold; margin-bottom: 8px; font-size: 14px;">Human-level 3D Mental Models</div>
                                    <div style="font-size: 13px; line-height: 1.6; color: #555;">
                                        ▸ Generative worlds<br>
                                        <span style="margin-left: 12px; color: #888; font-size: 12px;">(<a href="https://openreview.net/pdf?id=8NlUL0Cv1L" class="navyblue" style="font-size: 12px;">GenEx</a>, ICLR'25, JHU news)</span><br>
                                        ▸ 4D analysis-by-synthsis <br>
                                        <span style="margin-left: 12px; color: #888; font-size: 12px;">(<a href="https://arxiv.org/pdf/2507.10437" class="navyblue" style="font-size: 12px;">4D-Animal</a>, WACV'26)</span><br>
                                        ▸ 3D/4D spatial reasoning<br>
                                        <span style="margin-left: 12px; color: #888; font-size: 12px;">(<a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_SpatialLLM_A_Compound_3D-Informed_Design_towards_Spatially-Intelligent_Large_Multimodal_Models_CVPR_2025_paper.pdf" class="navyblue" style="font-size: 12px;">SpatialLLM</a>, CVPR'25 highlight)</span>
                                    </div>
                                </div>
                                
                                <!-- Arrow -->
                                <div style="font-size: 32px; color: #666;">→</div>
                                
                                <!-- Right: Embodiment -->
                                <div style="text-align: center;">
                                    <div style="font-weight: bold; font-size: 14px; margin-bottom: 8px;">Closed-Loop Embodiment</div>
                                    <div style="font-size: 13px; color: #555;">
                                        Generation, perception, and action within physical world<br>
                                        <span style="color: #888; font-size: 12px;">(<a href="https://arxiv.org/pdf/2510.18135" class="navyblue" style="font-size: 12px;">World-in-World</a>, ICLR'26)</span>
                                    </div>
                                </div>
                            </div>

                        </div>

                        <!-- Block 2: Proactive Medical Intelligence -->
                        <div class="research-block">
                            <div class="block-header">
                                <div class="block-title">Proactive Biomedical Systems</div>
                            </div>
                            
                           <div style="display: grid; grid-template-columns: 1fr auto 1fr; gap: 15px; align-items: center; margin-bottom: 25px; padding: 15px; background: white; border: 1px solid #ddd; border-radius: 8px;">
                                <!-- Left: Scalable Diagnosis -->
                                <div style="text-align: center;">
                                    <div style="font-weight: bold; margin-bottom: 8px; font-size: 14px;">Scalable Early Diagnosis</div>
                                    <div style="font-size: 13px; line-height: 1.6; color: #555;">
                                        ▸ Scaling eight-major cancer AI<br>
                                        <span style="margin-left: 12px; color: #888; font-size: 12px;">(<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CancerUniT_Towards_a_Single_Unified_Model_for_Effective_Detection_Segmentation_ICCV_2023_paper.pdf" class="navyblue" style="font-size: 12px;">CancerUnit</a>, ICCV'23)</span><br>
                                        ▸ Scaling cancer AI with reports<br>
                                        <span style="margin-left: 12px; color: #888; font-size: 12px;">(<a href="https://papers.miccai.org/miccai-2025/paper/0049_paper.pdf" class="navyblue" style="font-size: 12px;">R-Super</a>, MICCAI'25)</span>
                                    </div>
                                </div>
                                
                                <!-- Arrow -->
                                <div style="font-size: 32px; color: #666;">→</div>
                                
                                <!-- Right: Matched Treatment -->
                                <div style="text-align: center;">
                                    <div style="font-weight: bold; font-size: 14px; margin-bottom: 8px;">Treatment Discovery</div>
                                    <div style="font-size: 13px; color: #555;">
                                        Personalized treatment<br>
                                        planning via simulation<br>
                                        <span style="color: #888; font-size: 12px;">(<a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Yang_Medical_World_Model_ICCV_2025_paper.pdf" class="navyblue" style="font-size: 12px;">Medical World Model</a>, ICCV'25)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Arrow indicators -->
                    <div class="arrow-container">
                        <div class="arrow">
                            <div class="arrow-icon">↑</div>
                        </div>
                        <div class="arrow">
                            <div class="arrow-icon">↑</div>
                        </div>
                    </div>

                    <!-- Block 3: Foundation Neural Architecture -->
                    <div class="research-block foundation-block">
                        <div class="block-header">
                            <div class="block-title">Foundation Neural Architecture</div>
                        </div>
                        
                                                <div style="display: grid; grid-template-columns: 1fr auto 1fr; gap: 15px; align-items: center; margin-bottom: 25px; padding: 15px; background: white; border: 1px solid #ddd; border-radius: 8px;">
                            <!-- Left: Visual Dense Prediction -->
                            <div style="text-align: center;">
                                <div style="font-weight: bold; margin-bottom: 8px; font-size: 14px;">Visual Dense Learning</div>
                                <div style="font-size: 13px; line-height: 1.6; color: #555;">
                                    ▸ <a href="https://arxiv.org/pdf/2102.04306" class="navyblue" style="font-size: 12px;">TransUNet</a>: the first scalable Transformer architecture that fuse global attention with U-Net's local comprehension. <br>
                                    ▸ <a href="https://arxiv.org/pdf/2105.05537" class="navyblue" style="font-size: 12px;">Swin-Unet</a>: upgrade TransUNet through pure attention.<br>
                                    ▸ <a href="https://ojs.aaai.org/index.php/AAAI/article/view/19967" class="navyblue" style="font-size: 12px;">TransFG</a>: introduced novel part-level attention. 
                                </div>
                            </div>
                            
                            <!-- Arrow -->
                            <div style="font-size: 32px; color: #666;">→</div>
                            
                            <!-- Right: Multimodal Architecture -->
                            <div style="text-align: center;">
                                <div style="font-weight: bold; font-size: 14px; margin-bottom: 8px;">Multimodal Learning</div>
                                <div style="font-size: 13px; color: #555;">
                                    ▸ Visual Encoder <span style="margin-left: 12px; color: #888; font-size: 12px;">(<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_ViTamin_Designing_Scalable_Vision_Models_in_the_Vision-Language_Era_CVPR_2024_paper.pdf" class="navyblue" style="font-size: 12px;">ViTamin</a>, CVPR'24)</span> <br>
                                    ▸ Visual representation in language models <span style="margin-left: 12px; color: #888; font-size: 12px;">(<a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/871ed095b734818cfba48db6aeb25a62-Paper-Conference.pdf" class="navyblue" style="font-size: 12px;">LLaVolta</a>, NeurIPS'24)</span><br>
                                </div>
                            </div>
                        </div>

                        <!-- Recognition -->
                        <ul style="list-style-type: none; padding-left: 0px; margin-top: 15px;">
                            <li style="margin-bottom: 8px;"><i class="fa fa-star" style="color: #888; font-size: 12px; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle; font-size: 12px;"><a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yLYj88sAAAAJ&citation_for_view=yLYj88sAAAAJ:dhFuZR0502QC" class="navyblue" style="font-size: 12px;">TransUNet</a> is listed as <a href="https://gist.github.com/sergicastellasape/185f72fece3bb489f79366908594504d" class="navyblue" style="font-size: 12px;">top 15 cited 2021 paper in all AI fields</a> (the top 1 alphafold has won the nobel prize).</span></li>
                            <li style="margin-bottom: 8px;"><i class="fa fa-star" style="color: #888; font-size: 12px; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle; font-size: 12px;"><a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yLYj88sAAAAJ&citation_for_view=yLYj88sAAAAJ:BqipwSGYUEgC" class="navyblue" style="font-size: 12px;">SwinUNet</a> is listed as <a href="https://scholar.google.com/citations?hl=en&vq=en&view_op=list_hcore&venue=cwIh2C-xo8kJ.2025" class="navyblue" style="font-size: 12px;">top 3 most cited ECCV papers in five years in Google Metrics</a>.</span></li>
                            <li style="margin-bottom: 8px;"><i class="fa fa-star" style="color: #888; font-size: 12px; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle; font-size: 12px;"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/19967" class="navyblue" style="font-size: 12px;">TransFG</a> listed among <a href="https://www.paperdigest.org/2023/04/most-influential-aaai-papers-2023-04/" class="navyblue" style="font-size: 12px;">top 3 most influential AAAI papers</a>.</span></li>
                            <li style="margin-bottom: 8px;"><i class="fa fa-star" style="color: #888; font-size: 12px; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle; font-size: 12px;"><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_ViTamin_Designing_Scalable_Vision_Models_in_the_Vision-Language_Era_CVPR_2024_paper.pdf" class="navyblue" style="font-size: 12px;">ViTamin</a> achieved state-of-the-art on 60+ multimodal benchmarks in 2024, and was adopted into the widely used <a href="https://github.com/huggingface/pytorch-image-models" class="navyblue" style="font-size: 12px;">timm</a> (36k stars) and <a href="https://github.com/mlfoundations/open_clip" class="navyblue" style="font-size: 12px;">openclip</a> codebase (13k stars).</span></li>
                        </ul>
                    </div>






  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:10px;width:100%;vertical-align:middle">
          <heading>Recent Projects</heading>
        </td>
      </tr>
    </tbody>
  </table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>        
      <p><font size="4" style="position: relative; padding-left: 20px;"><a href="https://scholar.google.com/citations?hl=en&user=yLYj88sAAAAJ">Full list on Google Scholar Profile</a><smaller>.</smaller> </font> &star; denotes visiting undergraduate / graduate mentees. </p>


      <tr>
              <td class="pub-image-box">
          <div class="onewider">
                <img style="width:230px; height: auto;" src='images/world-in-world.png'>
          </div>
        </td>
        <td class="pub-text-box">
              <a href="https://arxiv.org/pdf/2510.18135">
                  <papertitle>World-in-World: World Models in a Closed-Loop World</papertitle>.
              </a>
              <p class="authors"> 
                <a href="https://arxiv.org/pdf/2510.18135", class="author">Jiahan Zhang*</a>&star;, 
                <a href="https://arxiv.org/pdf/2510.18135", class="author">Muqing Jiang*</a>&star;, 
                <a href="https://openreview.net/profile?id=~Nanru_Dai1", class="author">Nanru Dai</a>&star;, 
                <a href="https://taiminglu.com/" class="author">TaiMing Lu</a>&star;,
                <a href="https://scholar.google.com/citations?user=5fsB_GMAAAAJ", class="author">Arda Uzunoglu</a>&star;, 
                <a href="https://zssc.tech/", class="author">Shunchi Zhang</a>, 
                <a href="https://weiyana.github.io/", class="author">Yana Wei</a>, 
                <a href="https://jiahaoplus.github.io/", class="author">Jiahao Wang</a>, 
                <a href="https://engineering.jhu.edu/faculty/vishal-patel/", class="author">Vishal Patel</a>, 
                <a href="https://pliang279.github.io/", class="author">Paul Liang</a>, 
                <a href="https://danielkhashabi.com/" class="author">Daniel Khashabi</a>,
                <a href="https://www.zongweiz.com/", class="author">Cheng Peng</a>,
                <a href="https://engineering.jhu.edu/faculty/rama-chellappa/", class="author">Rama Chellappa</a>, 
                <a href="https://www.tshu.io/" class="author">Tianmin Shu</a>,
                <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Alan Yuille</a>,
                <a href="https://yilundu.github.io/" class="author">Yilun Du</a>,
                Jieneng Chen.
              </p>
              <p class="conference">
                <font color="DarkRed">ICLR</font>, 2026.
              </p>
              <p class="conference">
                <font color="DarkRed">Oral presentation</font> (4% of accepted papers).
              </p>
              <p class="abstract">
                World models live and die by their closed-loop success, not flawless generated visuals.
              </p>
              <a href="https://arxiv.org/pdf/2510.18135", class="navyblue">Paper</a>  | <a href="https://openreview.net/forum?id=yDmb7xAfeb", class="navyblue">OpenReview</a> | <a href="https://world-in-world.github.io/", class="navyblue">Project</a> | <a href="https://world-in-world.github.io/subpages/leaderboard.html", class="navyblue">Leaderboard</a> | <a href="https://world-in-world.github.io/subpages/index.html", class="navyblue">Interactive Demo</a>  | <a href="https://github.com/World-In-World/world-in-world", class="navyblue">Code</a> 
             <br>
             <br>
         </td>
      </tr>


      <tr>
         <td class="pub-image-box">
          <div class="one">
            <video width="230px" height="auto" autoplay loop muted>
              <source src="images/4d-animal.mp4" type="video/mp4">
            </video>
          </div>
        </td>
        <td class="pub-text-box">
              <a href="https://arxiv.org/pdf/2507.10437">
                  <papertitle>4D-Animal: Freely Reconstructing Animatable 3D Animals from Videos</papertitle>.
              </a>
              <br>

              <a href="https://zhongshsh.github.io/", class="author">Shanshan Zhong</a> &star;, 
              <a href="https://scholar.google.com/citations?user=4jdUy5AAAAAJ", class="author">Jiawei Peng</a>, 
              <a href="https://scholar.google.com/citations?user=Pig6X6MAAAAJ", class="author">Zehan Zheng</a>, 
              <a href="https://scholar.google.com/citations?user=R-b68CEAAAAJ", class="author">Zhongzhan Huang</a>,
              <a href="https://scholar.google.com/citations?user=mYkvHdIAAAAJ", class="author">Wufei Ma</a>,
              <a href="https://scholar.google.com/citations?user=vl0mzhEAAAAJ&hl=en", class="author">Guofeng Zhang</a>,
              <a href="https://scholar.google.com/citations?user=WFl3hH0AAAAJ&hl", class="author">Qihao Liu</a>,
              <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Alan Yuille</a>,
              Jieneng Chen
              <br>
              <p></p>
              <font color="DarkRed">WACV</font>, 2026.
              <br>
              <a href="https://arxiv.org/pdf/2507.10437", class="navyblue">Paper</a> | <a href="https://github.com/zhongshsh/4D-Animal", class="navyblue">Code</a>
             <br>
         </td>
      </tr>


      <tr>
        <td class="pub-image-box">
          <div class="one">
            <video width="230px" height="auto" autoplay loop muted>
              <source src="images/genex.mp4" type="video/mp4">
            </video>
          </div>
        </td>
        <td class="pub-text-box">
          <a href="https://openreview.net/pdf?id=8NlUL0Cv1L">
            <papertitle>GenEx: Generating an Explorable World</papertitle>.
          </a>
          <p class="authors">
            <a href="https://taiminglu.com/" class="author">TaiMing Lu</a> &star;,
            <a href="https://www.tshu.io/" class="author">Tianmin Shu</a>,
            <a href="https://www.cs.jhu.edu/~ayuille/" class="author">Alan Yuille</a>,
            <a href="https://danielkhashabi.com/" class="author">Daniel Khashabi</a>,
            Jieneng Chen.
          </p>
          <p class="conference">
            <font color="DarkRed">ICLR</font>, 2025.
          </p>

          <p class="abstract">
            Turn a single image into a 3D world adventure.
          </p>
          <p class="abstract">
            Embodied agents refine their beliefs by predicting unseen parts of the physical world.
          </p>
          <p class="links">
            <font color="DarkRed"><a href="https://hub.jhu.edu/2024/12/19/a-generated-world-of-pure-imagination/" class="navyblue">JHU News</a></font> | 
            <a href="https://openreview.net/pdf?id=8NlUL0Cv1L", class="navyblue">Paper (OpenReview)</a> |
            <a href="https://arxiv.org/pdf/2412.09624", class="navyblue">Blog</a> |
            <a href="https://genex.world/", class="navyblue">Project Website</a>
          </p>
          <br>
        </td>
      </tr>


      <tr>
        <td class="pub-image-box">
          <div class="one">
            <video width="230px" height="auto" autoplay loop muted>
              <source src="images/mewm-480p.mov" type="video/mp4">
            </video>
          </div>
        </td>
        <td class="pub-text-box">
              <a href="https://arxiv.org/pdf/2506.02327">
                  <papertitle>Medical World Model: Generative Simulation of Tumor Evolution for Treatment Planning</papertitle>.
              </a>
              <p class="authors">
                <a href="https://yijun-yang.github.io/", class="author">Yijun Yang</a> &star;, 
                <a href="https://aiem.jhu.edu/people/zhaoyang-wang/", class="author">Zhao-Yang Wang</a>, 
                <a href="https://github.io/", class="author">Qiuping Liu</a>, 
                <a href="https://github.io/", class="author">Shuwen Sun</a>, 
                <a href="https://radiology.ucsf.edu/people/kang-wang", class="author">Kang Wang</a>, 
                <a href="https://engineering.jhu.edu/faculty/rama-chellappa/", class="author">Rama Chellappa</a>, 
                <a href="https://www.zongweiz.com/", class="author">Zongwei Zhou</a>, 
                <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Alan Yuille</a>, 
                <a href="https://sites.google.com/site/indexlzhu/home", class="author">Lei Zhu</a>, 
                <a href="https://github.io/", class="author">Yu-Dong Zhang</a>,
                Jieneng Chen.
              </p>
              <p class="conference">
                <font color="DarkRed">ICCV</font>, 2025.
              </p>
              <p class="abstract">
                Envision precision medicine via generative world modeling.
              </p>
              <a href="https://arxiv.org/pdf/2506.02327", class="navyblue">Paper</a> | <a href="https://github.com/scott-yjyang/MeWM", class="navyblue">Code</a> |
                    <a href="https://yijun-yang.github.io/MeWM/", class="navyblue">Project</a>
             <br>
             <br>
         </td>
      </tr>

        <td class="pub-image-box">
          <div class="onewider">
                <img style="width:230px; height: auto;" src='images/evoworld.png'>
          </div>
        </td>
        <td class="pub-text-box">
              <a href="https://arxiv.org/abs/2510.01183">
                  <papertitle>EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory</papertitle>.
              </a>

              <p class="authors"> 
                <a href="https://jiahaoplus.github.io/", class="author">Jiahao Wang*</a>, 
                <a href="", class="author">Luoxin Ye*</a>, 
                <a href="https://taiminglu.com/" class="author">TaiMing Lu</a>,
                <a href="https://lambert-x.github.io/" class="author">Junfei Xiao</a>,
                <a href="https://engineering.jhu.edu", class="author">Jiahan Zhang</a>, 
                <a href="https://engineering.jhu.edu", class="author">Yuxiang Guo</a>, 
                <a href="https://engineering.jhu.edu", class="author">Xijun Liu</a>, 
                <a href="https://engineering.jhu.edu/faculty/rama-chellappa/", class="author">Rama Chellappa</a>, 
                <a href="https://www.zongweiz.com/", class="author">Cheng Peng</a>, 
                <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Alan Yuille</a>,
                Jieneng Chen.
              </p>
              <p class="conference">
                Technical report, 2025.
              </p>
              <p class="abstract">
                Bridge generative world models with 3D vision.
              </p>
              <a href="https://arxiv.org/abs/2510.01183", class="navyblue">Paper</a> | <a href="https://github.com/JiahaoPlus/EvoWorld", class="navyblue">Code</a> 
             <br>
             <br>
         </td>
      </tr>



      <tr>
        <td class="pub-image-box">
          <div class="onewider">
            <!-- <div class="twowider" id='spatialllm'><img style="width:100%; height: auto;" src='images/spatial457.png'></div> -->
                <img style="width:230px; height: auto;" src='images/vlv.png'>
          </div>
        </td>
        <td class="pub-text-box">
              <a href="https://lambert-x.github.io/Vision-Language-Vision/">
                  <papertitle>Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models</papertitle>.
              </a>
              <br>

              <a href="https://cogsci.jhu.edu/directory/tiezheng-zhang/", class="author">Tiezheng Zhang</a>, 
              <a href="https://lyttttt3333.github.io/YitongLi.github.io/", class="author">Yitong Li</a>, 
              <a href="https://sites.google.com/view/yu-cheng-chou", class="author">Yu-Cheng Chou</a>, 
              Jieneng Chen,
              <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Alan Yuille</a>,
              <a href="https://weichen582.github.io/", class="author">Chen Wei</a>,
              <a href="https://lambert-x.github.io/", class="author">Junfei Xiao</a>.
              <br>
              <p></p>
              <font color="DarkRed">NeurIPS</font>, 2025.
              <br>
              <a href="https://arxiv.org/pdf/2507.07104", class="navyblue">Paper</a> | <a href="https://lambert-x.github.io/Vision-Language-Vision/", class="navyblue">Project</a> | <a href="https://github.com/Tiezheng11/Vision-Language-Vision", class="navyblue">Code</a> | <a href="https://huggingface.co/datasets/ccvl/LAION-High-Qualtiy-Pro-6M-VLV", class="navyblue">HuggingFace Data Card </a>
             <br>
         </td>
      </tr>
      
      <tr>
        <td class="pub-image-box">
          <div class="onewider">
            <!-- <div class="twowider" id='spatialllm'><img style="width:100%; height: auto;" src='images/spatial457.png'></div> -->
                <img style="width:230px; height: auto;" src='images/spatial457.png'>
          </div>
        </td>
        <td class="pub-text-box">
              <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Spatial457_A_Diagnostic_Benchmark_for_6D_Spatial_Reasoning_of_Large_CVPR_2025_paper.pdf">
                  <papertitle>Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models</papertitle>.
              </a>
              <br>

              <a href="https://xingruiwang.github.io/", class="author">Xingrui Wang</a>, 
              <a href="https://wufeim.github.io/", class="author">Wufei Ma</a>, 
              <a href="https://ollie-ztz.github.io/Tiezheng.github.io/", class="author">Tiezheng Zhang</a>, 
              <a href="https://celsodemelo.net/", class="author">Celso Miguel de Melo</a>,
              Jieneng Chen&dagger;,
              <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Alan Yuille</a>&dagger;.
              <br>
              <p></p>
              <font color="DarkRed">CVPR</font>, 2025.
              <p></p>
              <font color="DarkRed">Highlight presentation</font>
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Spatial457_A_Diagnostic_Benchmark_for_6D_Spatial_Reasoning_of_Large_CVPR_2025_paper.pdf", class="navyblue">Paper camera ready</a> | <a href="https://github.com/XingruiWang/Spatial457", class="navyblue">Code</a> | <a href="https://huggingface.co/datasets/RyanWW/Spatial457", class="navyblue">HuggingFace Data Card </a>
             <br>
         </td>
      </tr>

      <tr>
        <td class="pub-image-box">
          <div class="onewider">
            <!-- <div class="twowider" id='spatialllm'><img style="width:100%; height: auto;" src='images/spatialllm.png'></div> -->
                <img style="width:230px; height: auto;" src='images/spatialllm.png'>
          </div>
        </td>
        <td class="pub-text-box">
              <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_SpatialLLM_A_Compound_3D-Informed_Design_towards_Spatially-Intelligent_Large_Multimodal_Models_CVPR_2025_paper.pdf">
                  <papertitle>SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models</papertitle>.
              </a>
              <br>
              <a href="https://wufeim.github.io/", class="author">Wufei Ma</a>, 
              <a href="https://openreview.net/profile?id=~Luoxin_Ye1", class="author">Luoxin Ye</a>, 
              <a href="https://github.io/", class="author">Nessa McWeeney</a>, 
              <a href="https://celsodemelo.net/", class="author">Celso Miguel de Melo</a>,
              <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Alan Yuille</a>,
              Jieneng Chen.
              <!-- Jieneng Chen<sup><i class="fa-regular fa-envelope fa-xs"></i></sup></strong>. -->
              <br>
              <p></p>
              <font color="DarkRed">CVPR</font>, 2025.
              <p></p>
              <font color="DarkRed">Highlight presentation</font>
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_SpatialLLM_A_Compound_3D-Informed_Design_towards_Spatially-Intelligent_Large_Multimodal_Models_CVPR_2025_paper.pdf", class="navyblue">Paper camera ready</a>
              <br>
          </td>
      </tr>


      <tr>
        <td class="pub-image-box">
          <div class="onewider">
                <img style="width:230px; height: auto;" src='images/llavolta.png'>
          </div>
        </td>
        <td class="pub-text-box">
              <a href="https://arxiv.org/abs/2406.20092">
                  <papertitle>LLaVolta: Efficient Large Multi-modal Models via Visual Context Compression</papertitle>.
              </a>
              <br>
              Jieneng Chen, 
              <a href="https://openreview.net/profile?id=~Luoxin_Ye1", class="author">Luoxin Ye</a>,
              <a href="https://tacju.github.io/", class="author">Ju He</a>,
              <a href="https://aiem.jhu.edu/people/zhaoyang-wang/", class="author">Zhaoyang Wang</a>,
              <a href="https://danielkhashabi.com/", class="author">Daniel Khashabi</a>,
              <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Alan Yuille</a>.
              <br>
              <p></p>
              <font color="DarkRed">NeurIPS</font>, 2024.
              <br>
              <a href="https://arxiv.org/pdf/2406.20092", class="navyblue">Paper</a> |
                  <a href="https://github.com/Beckschen/LLaVolta", class="navyblue">Code</a> |
                    <a href="https://beckschen.github.io/llavolta.html", class="navyblue">Project</a>
             <br>
         </td>
     </tr>

      <tr>
        <td class="pub-image-box">
          <div class="onewider">
                <img style="width:230px; height: auto;" src='images/vitamin.png'>
          </div>
        </td>
        <td class="pub-text-box">
              <a href="https://arxiv.org/pdf/2404.02132.pdf">
                  <papertitle>ViTamin: Designing Scalable Vision Models in the Vision-Language Era</papertitle>.
              </a>
              <br>
              Jieneng Chen, 
              <a href="https://www.cs.jhu.edu/~ayuille/", class="author"> Qihang Yu</a>, 
              <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Xiaohui Shen</a>, 
              <a href="https://www.cs.jhu.edu/~ayuille/", class="author">Alan Yuille</a>, 
              <a href="http://liangchiehchen.com/", class="author">Liang-Chieh Chen</a>.
              <br>
              <p></p>
              <font color="DarkRed">CVPR</font>, 2024.
              <br>
              The first vision-centric design for LMM encoder, with SoTA performance on 60+ multimodal tasks in 2024.
              <br>
              <a href="https://arxiv.org/pdf/2404.02132.pdf", class="navyblue">Paper</a> |
                  <a href="https://github.com/Beckschen/ViTamin", class="navyblue">Code</a> |
                    <a href="https://huggingface.co/jienengchen/ViTamin-XL-384px", class="navyblue">🤗 HuggingFace</a> | <a href="https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/vitamin.py", class="navyblue">timm</a> <img src="https://img.shields.io/github/stars/huggingface/pytorch-image-models?style=social&label=Star&maxAge=2592000" alt="GitHub Stars Badge" style="margin-top: -3px; width:auto; height:16px;"> | <a href="https://github.com/mlfoundations/open_clip/blob/main/src/open_clip/model_configs/ViTamin-XL-384.json", class="navyblue">open_clip</a> <img src="https://img.shields.io/github/stars/mlfoundations/open_clip?style=social&label=Star&maxAge=2592000" alt="GitHub Stars Badge" style="margin-top: -3px; width:auto; height:16px;">
              
            <br>
         </td>
     </tr>

     <tr>
      <td class="pub-image-box">
        <div class="onewider">
              <img style="width:230px; height: auto;" src='images/transunet.png'>
        </div>
      </td>
      <td class="pub-text-box">
                 <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056">
                     <papertitle>TransUNet: Rethinking the U-Net Architecture Design for Medical Image Segmentation through the Lens of Transformers</papertitle>.
                 </a>
                 <br>
                 Jieneng Chen, 
                 <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Jieru Mei</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Xianhang Li</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Yongyi Lu</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Qihang Yu</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Qingyue Wei</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Xiangde Luo</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Yutong Xie</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Ehsan Adeli</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Yan Wang</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Matthew P Lungren</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Shaoting Zhang</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Lei Xing</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Le Lu</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Alan Yuille</a>, 
                <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="author">Yuyin Zhou</a>.
                 <br>
                 <p></p>
                 <font color="DarkRed">Medical Image Analysis (MedIA)</font>, 2024.
                 <p></p>
                  <a href="https://arxiv.org/pdf/2102.04306.pdf", class="navyblue">ICML-W 2021</a> | 
                  <a href="https://www.sciencedirect.com/science/article/pii/S1361841524002056", class="navyblue">Journal</a> |
                  <a href="https://github.com/Beckschen/TransUNet", class="navyblue">Code</a> |
                  <img src="https://img.shields.io/github/stars/Beckschen/TransUNet?style=social&label=Star&maxAge=2592000" alt="GitHub Stars Badge" style="margin-top: -3px; width:auto; height:22px;"> 
                  <br>
                  Most downloaded articles published in ScienceDirect all time. 
                  <br>
                  Most cited articles in MedIA.
                  <br>
                  <i style="color: red;">Top 15 cited 2021 paper in all AI fields</i>.
                  
            <br>
         </td>

     </tr>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:10px;width:100%;vertical-align:middle">
            <heading>Talks</heading>
          </td>
        </tr>
      </tbody></table>

    <ul style="list-style-type: none; padding-left: 30px;">
        <li style="margin-bottom: 4px;">  <i class="fa fa-microphone" style="color: #4169E1; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">invited talk at <a href="https://iaifi.org/about.html", class="navyblue">NSF IAIFI</a> on physics & AI in Boston.</span>
        <li style="margin-bottom: 4px;">  <i class="fa fa-microphone" style="color: #4169E1; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">invited lab seminar at Stanford.</span>
        <li style="margin-bottom: 4px;">  <i class="fa fa-microphone" style="color: #4169E1; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">invited vision seminar at UIUC.</span>
        <li style="margin-bottom: 4px;">  <i class="fa fa-microphone" style="color: #4169E1; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">invited guest lecture at Rice University.</span>
        <li style="margin-bottom: 4px;">  <i class="fa fa-microphone" style="color: #4169E1; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">invited lab seminars at Harvard/MIT/HMS/MGH/Dana-Farber.</span>
        <li style="margin-bottom: 4px;">  <i class="fa fa-microphone" style="color: #4169E1; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">invited talk at ICLR 2025 Workshop on <a href="https://embodiedcity.github.io/iclr25-workshop/", class="navyblue">Embodied Intelligence with LLMs In Open City Environment</a> (<a href="https://beckschen.github.io/talks/Talk_Genex_20250427_Jieneng_Chen.pdf", class="navyblue">slides</a>).</span>
        <li style="margin-bottom: 4px;">  <i class="fa fa-microphone" style="color: #4169E1; vertical-align: middle; width: 20px; text-align: center;"></i> <span style="vertical-align: middle;">invited talks at Johns Hopkins, <a href="https://engineering.jhu.edu/chembe/", class="navyblue">Chemical and Biomolecular Engineering</a> (ChemBE), <a href="https://cogsci.jhu.edu/event/brown-bag-talk-jieneng-chen/", class="navyblue">Cognitive Science Brown Bag</a>, Center for Language and Speech Processing (CLSP), Mathematical Institute for Data Science (MINDS), Artificial Intelligence for Engineering and Medicine Lab (AIEM). </span>
      </ul>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:10px;width:100%;vertical-align:middle">
            <heading>Teaching</heading>
          </td>
        </tr>
      </tbody></table>
      <ul> 
        <li><strong>Instructor</strong>: I designed and taught the undergraduate course Machine Imagination, EN.601.208, at JHU in 2025 and 2026 (starting Jan. 2026). </li> 
      </ul>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:10px;width:100%;vertical-align:middle">
          <heading>Service</heading>
        </td>
      </tr>
    </tbody></table>
    <ul> 
      <li>Invited reviewers: CVPR, ICCV, ECCV, WACV, NeurIPS, ICML, ICLR, AAAI, IJCV, TPAMI, TMI, MICCAI and CogSci. 
      </li> 
      <li>Workshop co-organizer for ICCV, CVPR and MICCAI.
      </li>
      <li>JHU CS mentor hours.
      </li> 
      <li>Lecture for JHU WSE Pre-College Program 2025.
        </li> 
    </ul>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:10px;width:100%;vertical-align:middle">
        <heading>Mentoring</heading>
      </td>
    </tr>
  </tbody></table>
    <p style="margin-left: 30px; color: #666; font-style: italic; margin-bottom: 10px;">I am fortunate to have collaborated with super talented students at JHU.</p>
    
    <ul>
        <li style="margin-bottom: 8px;">
            <a href="https://taiminglu.com/" class="navyblue">TaiMing Lu</a>, JHU Undergraduate → Princeton CS PhD<br>
            <span style="margin-left: 0px; color: #666; font-style: italic; margin-bottom: 10px;"> 
            Research: 1 first-author ICLR publication (the Genex project). <br>
            <span style="margin-left: 0px; color: #666; font-style: italic; margin-bottom: 10px;"> 
            Award: <a href="https://www.cs.jhu.edu/news/celebrating-the-2025-department-and-school-awardees/" class="navyblue">Michael J. Muuss Research Award</a> and 
            finalist for <a href="https://cra.org/about/awards/outstanding-undergraduate-researcher-award/" class="navyblue">the CRA Outstanding Undergraduate Researcher Award</a>.</span>
        </li>
        <li style="margin-bottom: 8px;">
            <a href="https://zhongshsh.github.io/" class="navyblue">Shanshan Zhong</a> (she/her), SYSU MS → CMU LTI PhD<br>
            <span style="margin-left: 0px; color: #666; font-style: italic; margin-bottom: 10px;"> 
            Research: 1 first-author WACV publication (the 4D-Animal project).
        </li>
    </ul>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:10px;width:100%;vertical-align:middle">
        <heading>Acknowledgement</heading>
      </td>
    </tr>
  </tbody></table>
      <ul>
    <span style="margin-left: 0px; margin-bottom: 10px;"> 
    My doctoral research was made possible through the generous support of ARL, IARPA, NSF, NIH, ONR, Lambda, NVIDIA, Johns Hopkins University, the Siebel Foundation, the Patrick J. McGovern Foundation, and the Lustgarten Foundation. I am deeply grateful for the resources provided to me and my advisors.
    </ul>

 <script xml:space="preserve" language="JavaScript">
 hideallbibs();
 </script>

 <!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-131560165-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

<div style="margin-bottom: 50px;"></div>

</body>

</html>
